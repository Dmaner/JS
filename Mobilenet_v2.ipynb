{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mobilenet_v2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "4cFkOHBpvVxC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# The  keras implementation of mobilenet v2"
      ]
    },
    {
      "metadata": {
        "id": "GTCe29PD2Wok",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*load cifar10 as for test dataset*"
      ]
    },
    {
      "metadata": {
        "id": "ptXkV_cxxPl0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "55cc7da1-3559-4a95-f7f3-93422b39eafc"
      },
      "cell_type": "code",
      "source": [
        "!pip install keras\n",
        "!pip install pydot\n",
        "!pip install opencv-python"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.1.6)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (0.19.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.11.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.8.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.14.6)\n",
            "Collecting pydot\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/f1/e61d6dfe6c1768ed2529761a68f70939e2569da043e9f15a8d84bf56cadf/pydot-1.2.4.tar.gz (132kB)\n",
            "\u001b[K    100% |████████████████████████████████| 133kB 8.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.6/dist-packages (from pydot) (2.2.2)\n",
            "Building wheels for collected packages: pydot\n",
            "  Running setup.py bdist_wheel for pydot ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/6a/a5/14/25541ebcdeaf97a37b6d05c7ff15f5bd20f5e91b99d313e5b4\n",
            "Successfully built pydot\n",
            "Installing collected packages: pydot\n",
            "Successfully installed pydot-1.2.4\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (3.4.3.18)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python) (1.14.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "W8sefCFovGx4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "476b43bd-de8a-4ed7-df20-a767179b8128"
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import cifar10\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "import cv2\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "ihSkCk8dvVc2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "071b8e0d-14b9-4702-c3ea-49c8f69b355a"
      },
      "cell_type": "code",
      "source": [
        "# load data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 27s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZtN-lQ1Mydpj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "bd7dc806-152a-4001-a4ec-1cfc9ff6e185"
      },
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "class_names = [\n",
        "    'airplane', \n",
        "    'automobile',\n",
        "    'bird',\n",
        "    'cat',\n",
        "    'deer',\n",
        "    'dog',\n",
        "    'frog',\n",
        "    'horse',\n",
        "    'ship',\n",
        "    'truck'\n",
        "]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bky7LMYDzBng",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "c380c59b-633f-466f-fc82-1143d543b8c4"
      },
      "cell_type": "code",
      "source": [
        "#show some random image\n",
        "idx = randint(0,x_train.shape[0])\n",
        "image = x_train[idx]\n",
        "label = y_train[idx]\n",
        "plt.imshow(image)\n",
        "plt.title(class_names[int(label)])\n",
        "plt.axis('off')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-0.5, 31.5, 31.5, -0.5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAEHCAYAAACHl1tOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f8c94a28ef0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "flFMnAWtot_R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "f7419544-151c-4617-e9a7-be5247d167ce"
      },
      "cell_type": "code",
      "source": [
        "# save the data and make dir\n",
        "train_path = 'data//train//'\n",
        "test_path = 'data//test//'\n",
        "\n",
        "#save the image\n",
        "for i in range(len(x_train)):\n",
        "  x = x_train[i]\n",
        "  y = y_train[i]\n",
        "  path = train_path + str(y[0])\n",
        "  x = cv2.resize(x, (224, 224), interpolation=cv2.INTER_CUBIC)\n",
        "  if not os.path.exists(path):\n",
        "      os.makedirs(path)\n",
        "  cv2.imwrite(path + '//' + str(i) + '.jpg', x)\n",
        "print('Train data saved')\n",
        "  \n",
        "for i in range(len(x_test)):\n",
        "  x = x_test[i]\n",
        "  y = y_test[i]\n",
        "  path = test_path + str(y[0])\n",
        "  x = cv2.resize(x, (224, 224), interpolation=cv2.INTER_CUBIC)\n",
        "  if not os.path.exists(path):\n",
        "      os.makedirs(path)\n",
        "  cv2.imwrite(path + '//' + str(i) + '.jpg', x)\n",
        "print('Test data saved')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train data saved\n",
            "Test data saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "t-jytLVKtbU0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7db245e9-3402-4830-cd9f-2989965e9645"
      },
      "cell_type": "code",
      "source": [
        "print(os.listdir(train_path))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['3', '4', '5', '9', '1', '6', '2', '8', '0', '7']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KsC2u7Lv2hLv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Build the Mobilenet v2"
      ]
    },
    {
      "metadata": {
        "id": "Nx-j8_ZE2y20",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*The constructure of network*"
      ]
    },
    {
      "metadata": {
        "id": "z3nz0IgV3Gs5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![替代文字](https://github.com/xiaochus/MobileNetV2/raw/master/images/net.jpg)"
      ]
    },
    {
      "metadata": {
        "id": "-18PfgwQ2x2R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import keras\n",
        "\n",
        "\"\"\"MobileNet v2 models for Keras.\n",
        "# Reference\n",
        "- [Inverted Residuals and Linear Bottlenecks Mobile Networks for\n",
        "   Classification, Detection and Segmentation]\n",
        "   (https://arxiv.org/abs/1801.04381)\n",
        "\"\"\"\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, GlobalAveragePooling2D, Dropout\n",
        "from keras.layers import Activation, BatchNormalization, add, Reshape\n",
        "from keras.applications.mobilenet import relu6, DepthwiseConv2D\n",
        "from keras.utils.vis_utils import plot_model\n",
        "\n",
        "from keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jgruNlSw9adE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## *Def the conv2d layer and replace relu layer with relu6*"
      ]
    },
    {
      "metadata": {
        "id": "qI-yr7rE2qY0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _conv_block(inputs, filters, kernel, strides):\n",
        "    \"\"\"Convolution Block\n",
        "    This function defines a 2D convolution operation with BN and relu6.\n",
        "    # Arguments\n",
        "        inputs: Tensor, input tensor of conv layer.\n",
        "        filters: Integer, the dimensionality of the output space.\n",
        "        kernel: An integer or tuple/list of 2 integers, specifying the\n",
        "            width and height of the 2D convolution window.\n",
        "        strides: An integer or tuple/list of 2 integers,\n",
        "            specifying the strides of the convolution along the width and height.\n",
        "            Can be a single integer to specify the same value for\n",
        "            all spatial dimensions.\n",
        "    # Returns\n",
        "        Output tensor.\n",
        "    \"\"\"\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
        "\n",
        "    x = Conv2D(filters, kernel, padding='same', strides=strides)(inputs)\n",
        "    x = BatchNormalization(axis=channel_axis)(x)\n",
        "    return Activation(relu6)(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TO7WdFP49ttY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## *Def the bottleneck*"
      ]
    },
    {
      "metadata": {
        "id": "rekavFUt5-PG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _bottleneck(inputs, filters, kernel, t, s, r=False):\n",
        "    \"\"\"Bottleneck\n",
        "    This function defines a basic bottleneck structure.\n",
        "    # Arguments\n",
        "        inputs: Tensor, input tensor of conv layer.\n",
        "        filters: Integer, the dimensionality of the output space.\n",
        "        kernel: An integer or tuple/list of 2 integers, specifying the\n",
        "            width and height of the 2D convolution window.\n",
        "        t: Integer, expansion factor.\n",
        "            t is always applied to the input size.\n",
        "        s: An integer or tuple/list of 2 integers,specifying the strides\n",
        "            of the convolution along the width and height.Can be a single\n",
        "            integer to specify the same value for all spatial dimensions.\n",
        "        r: Boolean, Whether to use the residuals.\n",
        "    # Returns\n",
        "        Output tensor.\n",
        "    \"\"\"\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
        "    tchannel = K.int_shape(inputs)[channel_axis] * t\n",
        "\n",
        "    x = _conv_block(inputs, tchannel, (1, 1), (1, 1))\n",
        "\n",
        "    x = DepthwiseConv2D(kernel, strides=(s, s), depth_multiplier=1, padding='same')(x)\n",
        "    x = BatchNormalization(axis=channel_axis)(x)\n",
        "    x = Activation(relu6)(x)\n",
        "\n",
        "    x = Conv2D(filters, (1, 1), strides=(1, 1), padding='same')(x)\n",
        "    x = BatchNormalization(axis=channel_axis)(x)\n",
        "\n",
        "    if r:\n",
        "        x = add([x, inputs])\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RxcArehk94qB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## *Def the residual block*"
      ]
    },
    {
      "metadata": {
        "id": "Mocs76Pk6fk4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _inverted_residual_block(inputs, filters, kernel, t, strides, n):\n",
        "    \"\"\"Inverted Residual Block\n",
        "    This function defines a sequence of 1 or more identical layers.\n",
        "    # Arguments\n",
        "        inputs: Tensor, input tensor of conv layer.\n",
        "        filters: Integer, the dimensionality of the output space.\n",
        "        kernel: An integer or tuple/list of 2 integers, specifying the\n",
        "            width and height of the 2D convolution window.\n",
        "        t: Integer, expansion factor.\n",
        "            t is always applied to the input size.\n",
        "        s: An integer or tuple/list of 2 integers,specifying the strides\n",
        "            of the convolution along the width and height.Can be a single\n",
        "            integer to specify the same value for all spatial dimensions.\n",
        "        n: Integer, layer repeat times.\n",
        "    # Returns\n",
        "        Output tensor.\n",
        "    \"\"\"\n",
        "\n",
        "    x = _bottleneck(inputs, filters, kernel, t, strides)\n",
        "\n",
        "    for i in range(1, n):\n",
        "        x = _bottleneck(x, filters, kernel, t, 1, True)\n",
        "\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JORVy4EM9_qL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## *Build the whole model*"
      ]
    },
    {
      "metadata": {
        "id": "pSwlaHuH7zos",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def MobileNetv2(input_shape, k):\n",
        "    \"\"\"MobileNetv2\n",
        "    This function defines a MobileNetv2 architectures.\n",
        "    # Arguments\n",
        "        input_shape: An integer or tuple/list of 3 integers, shape\n",
        "            of input tensor.\n",
        "        k: Integer, number of classes.\n",
        "    # Returns\n",
        "        MobileNetv2 model.\n",
        "    \"\"\"\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = _conv_block(inputs, 32, (3, 3), strides=(2, 2))\n",
        "\n",
        "    x = _inverted_residual_block(x, 16, (3, 3), t=1, strides=1, n=1)\n",
        "    x = _inverted_residual_block(x, 24, (3, 3), t=6, strides=2, n=2)\n",
        "    x = _inverted_residual_block(x, 32, (3, 3), t=6, strides=2, n=3)\n",
        "    x = _inverted_residual_block(x, 64, (3, 3), t=6, strides=2, n=4)\n",
        "    x = _inverted_residual_block(x, 96, (3, 3), t=6, strides=1, n=3)\n",
        "    x = _inverted_residual_block(x, 160, (3, 3), t=6, strides=2, n=3)\n",
        "    x = _inverted_residual_block(x, 320, (3, 3), t=6, strides=1, n=1)\n",
        "\n",
        "    x = _conv_block(x, 1280, (1, 1), strides=(1, 1))\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Reshape((1, 1, 1280))(x)\n",
        "    x = Dropout(0.3, name='Dropout')(x)\n",
        "    x = Conv2D(k, (1, 1), padding='same')(x)\n",
        "\n",
        "    x = Activation('softmax', name='softmax')(x)\n",
        "    output = Reshape((k,))(x)\n",
        "\n",
        "    model = Model(inputs, output)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b0W9tK0g-GfI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Preprocess the data and Normalization"
      ]
    },
    {
      "metadata": {
        "id": "-0bXouCT-iGg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#import the necessary \n",
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers import Conv2D, Reshape, Activation\n",
        "from keras.models import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7UHmydrumCA4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Hyperparameter\n",
        "batch = 32\n",
        "epoch = 10\n",
        "num_classes = len(class_names)\n",
        "image_size = 224\n",
        "use_pretrained_weight = False\n",
        "num_of_pretrained_classes = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "unpx9TSzn9jb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate(batch, image_size):\n",
        "  '''\n",
        "  preprocess the dataset\n",
        "  '''\n",
        "  gen1 = ImageDataGenerator(\n",
        "          rescale=1. / 255,\n",
        "          shear_range=0.2,\n",
        "          zoom_range=0.2,\n",
        "          rotation_range=90,\n",
        "          width_shift_range=0.2,\n",
        "          height_shift_range=0.2,\n",
        "          horizontal_flip=True)\n",
        "  gen2 = ImageDataGenerator(rescale=1. /255)\n",
        "\n",
        "  train_data = gen1.flow_from_directory(\n",
        "          train_path,\n",
        "          target_size=(image_size, image_size),\n",
        "          batch_size=batch,\n",
        "          class_mode='categorical')\n",
        "\n",
        "  test_data = gen2.flow_from_directory(\n",
        "          test_path,\n",
        "          target_size=(image_size, image_size),\n",
        "          batch_size=batch,\n",
        "          class_mode='categorical')\n",
        "  count1 = 0\n",
        "  for root, dirs, files in os.walk(train_path):\n",
        "      for each in files:\n",
        "          count1 += 1\n",
        "\n",
        "  count2 = 0\n",
        "  for root, dirs, files in os.walk(test_path):\n",
        "      for each in files:\n",
        "          count2 += 1\n",
        "\n",
        "  return train_data, test_data, count1, count2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dBfwiFRcqeEK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "1d0f1946-b88e-453d-8f4a-526039a65878"
      },
      "cell_type": "code",
      "source": [
        "train_data, test_data, count1, count2 = generate(batch, image_size)\n",
        "print(count1, count2)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 50000 images belonging to 10 classes.\n",
            "Found 10000 images belonging to 10 classes.\n",
            "50000 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bF60smYir2fr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*Whether to load pretrained model*"
      ]
    },
    {
      "metadata": {
        "id": "PdFOa_xZsCHC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def fine_tune(num_classes, weights, model):\n",
        "    \"\"\"Re-build model with current num_classes.\n",
        "    # Arguments\n",
        "        num_classes, Integer, The number of classes of dataset.\n",
        "        tune, String, The pre_trained model weights.\n",
        "        model, Model, The model structure.\n",
        "    \"\"\"\n",
        "    model.load_weights(weights)\n",
        "\n",
        "    x = model.get_layer('Dropout').output\n",
        "    x = Conv2D(num_classes, (1, 1), padding='same')(x)\n",
        "    x = Activation('softmax', name='softmax')(x)\n",
        "    output = Reshape((num_classes,))(x)\n",
        "\n",
        "    model = Model(inputs=model.input, outputs=output)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XRvWy7MDsiHD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Training"
      ]
    },
    {
      "metadata": {
        "id": "8NwYJBb1smOU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(batch, epochs, num_classes, size, weights, tclasses):\n",
        "    \"\"\"Train the model.\n",
        "    # Arguments\n",
        "        batch: Integer, The number of train samples per batch.\n",
        "        epochs: Integer, The number of train iterations.\n",
        "        num_classes, Integer, The number of classes of dataset.\n",
        "        size: Integer, image size.\n",
        "        weights, String, The pre_trained model weights.\n",
        "        tclasses, Integer, The number of classes of pre-trained model.\n",
        "    \"\"\"\n",
        "\n",
        "    train_generator, validation_generator, count1, count2 = generate(batch, size)\n",
        "\n",
        "    if weights:\n",
        "        model = MobileNetv2((size, size, 3), tclasses)\n",
        "        model = fine_tune(num_classes, weights, model)\n",
        "    else:\n",
        "        model = MobileNetv2((size, size, 3), num_classes)\n",
        "\n",
        "    opt = Adam()\n",
        "    earlystop = EarlyStopping(monitor='val_acc', patience=30, verbose=0, mode='auto')\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "    hist = model.fit_generator(\n",
        "        train_generator,\n",
        "        validation_data=validation_generator,\n",
        "        steps_per_epoch=count1 // batch,\n",
        "        validation_steps=count2 // batch,\n",
        "        epochs=epochs,\n",
        "        callbacks=[earlystop])\n",
        "\n",
        "    if not os.path.exists('model'):\n",
        "        os.makedirs('model')\n",
        "\n",
        "    df = pd.DataFrame.from_dict(hist.history)\n",
        "    df.to_csv('model/hist.csv', encoding='utf-8', index=False)\n",
        "    model.save_weights('model/weights.h5')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ElCjAUXLtn0i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train(batch, epoch, num_classes, image_size, use_pretrained_weight, num_of_pretrained_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}